nohup: ignoring input
INFO:     Will watch for changes in these directories: ['/home/mubeen/compliance-chatbot']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [94927] using WatchFiles
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
INFO:     Started server process [94930]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
Graph compiled successfully.
AI Service Initialized (Index loaded and graph agent ready).
INFO:     127.0.0.1:45010 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:35592 - "OPTIONS /api/v1/chat HTTP/1.1" 200 OK
INFO:     127.0.0.1:35592 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:35592 - "OPTIONS /api/v1/chat/ HTTP/1.1" 200 OK
--- Invoking Graph Agent for jurisdiction: DIFC ---
--- NODE: contextualize_query ---
  - Rephrasing query based on history.
  - Contextualized Query: What are the compliance requirements for banks operating in the ADGM, specifically regarding capital adequacy and other financial obligations?
--- NODE: analyze_query ---
  - Query Type: COMPLIANCE
  - Confidence: 0.9
  - Should Retrieve: True
  - Should Converse: True
--- CONDITIONAL: decide_next_steps ---
  - Decision: Hybrid approach - retrieve documents and converse
--- NODE: generate_conversational_response ---
  - Generated conversational response
--- NODE: retrieve_documents ---
  - Retrieving docs for: 'What are the compliance requirements for banks operating in the ADGM, specifically regarding capital adequacy and other financial obligations?' in DIFC
  - Retrieved 2 relevant documents
--- NODE: synthesize_response ---
  - Synthesized hybrid response
INFO:     127.0.0.1:35592 - "POST /api/v1/chat/ HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 93, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 144, in simple_response
    await self.app(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/routing.py", line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/routing.py", line 736, in app
    await route.handle(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/routing.py", line 290, in handle
    await self.app(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/routing.py", line 78, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/routing.py", line 75, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 302, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 215, in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/starlette/concurrency.py", line 38, in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py", line 2470, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py", line 967, in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/backend/api/v1/endpoints/chat.py", line 15, in handle_chat
    return ChatResponse(
           ^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/pydantic/main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 2 validation errors for ChatResponse
sources.0
  Input should be a valid dictionary [type=dict_type, input_value=Document(metadata={'coord...d or deceive the DFSA.'), input_type=Document]
    For further information visit https://errors.pydantic.dev/2.11/v/dict_type
sources.1
  Input should be a valid dictionary [type=dict_type, input_value=Document(metadata={'coord...ant authorities.\n\n7.'), input_type=Document]
    For further information visit https://errors.pydantic.dev/2.11/v/dict_type
WARNING:  WatchFiles detected changes in 'backend/api/v1/endpoints/chat.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [94930]
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
INFO:     Started server process [95814]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
Graph compiled successfully.
AI Service Initialized (Index loaded and graph agent ready).
INFO:     127.0.0.1:34698 - "OPTIONS /api/v1/chat HTTP/1.1" 200 OK
INFO:     127.0.0.1:34698 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:34698 - "OPTIONS /api/v1/chat/ HTTP/1.1" 200 OK
--- Invoking Graph Agent for jurisdiction: DIFC ---
--- NODE: contextualize_query ---
  - No chat history, using original query.
--- NODE: analyze_query ---
  - Query Type: COMPLIANCE
  - Confidence: 0.9
  - Should Retrieve: True
  - Should Converse: True
--- CONDITIONAL: decide_next_steps ---
  - Decision: Hybrid approach - retrieve documents and converse
--- NODE: generate_conversational_response ---
  - Generated conversational response
--- NODE: retrieve_documents ---
  - Retrieving docs for: 'What are the capital requirements for DIFC banks?' in DIFC
  - Retrieved 2 relevant documents
--- NODE: synthesize_response ---
  - Synthesized hybrid response
INFO:     127.0.0.1:34698 - "POST /api/v1/chat/ HTTP/1.1" 200 OK
WARNING:  WatchFiles detected changes in 'backend/api/v1/endpoints/chat.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [95814]
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
INFO:     Started server process [96908]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
Graph compiled successfully.
AI Service Initialized (Index loaded and graph agent ready).
INFO:     127.0.0.1:44986 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
--- Invoking Graph Agent for jurisdiction: DIFC ---
--- NODE: contextualize_query ---
  - No chat history, using original query.
--- NODE: analyze_query ---
  - Query Type: COMPLIANCE
  - Confidence: 0.9
  - Should Retrieve: True
  - Should Converse: True
--- CONDITIONAL: decide_next_steps ---
  - Decision: Hybrid approach - retrieve documents and converse
--- NODE: generate_conversational_response ---
  - Generated conversational response
--- NODE: retrieve_documents ---
  - Retrieving docs for: 'What are the capital requirements for DIFC banks?' in DIFC
  - Retrieved 2 relevant documents
--- NODE: synthesize_response ---
  - Synthesized hybrid response
INFO:     127.0.0.1:44986 - "POST /api/v1/chat/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:48830 - "OPTIONS /api/v1/chat HTTP/1.1" 200 OK
INFO:     127.0.0.1:48830 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:48830 - "OPTIONS /api/v1/chat/ HTTP/1.1" 200 OK
--- Invoking Graph Agent for jurisdiction: DIFC ---
--- NODE: contextualize_query ---
  - No chat history, using original query.
--- NODE: analyze_query ---
  - Query Type: COMPLIANCE
  - Confidence: 0.9
  - Should Retrieve: True
  - Should Converse: True
--- CONDITIONAL: decide_next_steps ---
  - Decision: Hybrid approach - retrieve documents and converse
--- NODE: generate_conversational_response ---
  - Generated conversational response
--- NODE: retrieve_documents ---
  - Retrieving docs for: 'what are the capital requirnments for bands' in DIFC
  - Retrieved 2 relevant documents
--- NODE: synthesize_response ---
  - Synthesized hybrid response
INFO:     127.0.0.1:48830 - "POST /api/v1/chat/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:44864 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:44864 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:41172 - "OPTIONS /api/v1/chat HTTP/1.1" 200 OK
INFO:     127.0.0.1:41172 - "POST /api/v1/chat HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:41172 - "OPTIONS /api/v1/chat/ HTTP/1.1" 200 OK
--- Invoking Graph Agent for jurisdiction: DIFC ---
--- NODE: contextualize_query ---
  - No chat history, using original query.
--- NODE: analyze_query ---
  - Query Type: COMPLIANCE
  - Confidence: 0.9
  - Should Retrieve: True
  - Should Converse: True
--- CONDITIONAL: decide_next_steps ---
  - Decision: Hybrid approach - retrieve documents and converse
--- NODE: generate_conversational_response ---
  - Generated conversational response
--- NODE: retrieve_documents ---
  - Retrieving docs for: 'what are the capital requirnment for financial services companies' in DIFC
  - Retrieved 3 relevant documents
--- NODE: synthesize_response ---
  - Synthesized hybrid response
INFO:     127.0.0.1:41172 - "POST /api/v1/chat/ HTTP/1.1" 200 OK
WARNING:  WatchFiles detected changes in 'backend/api/v1/openai_compat.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [96908]
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
INFO:     Started server process [99946]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
WARNING:  WatchFiles detected changes in 'backend/main.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [99946]
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
INFO:     Started server process [365]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
WARNING:  WatchFiles detected changes in 'backend/api/v1/openai_compat.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [365]
/home/mubeen/compliance-chatbot/backend/core/ai_service.py:11: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. 	from pydantic.v1 import BaseModel

  from backend.core.graph_agent import agent, AgentState
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method="json_schema". Please use method="function_calling" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method="function_calling".
  warnings.warn(
/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1857: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.
  warnings.warn(
Process SpawnProcess-6:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 67, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 71, in serve
    await self._serve(sockets)
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 78, in _serve
    config.load()
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 436, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mubeen/compliance-chatbot/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/mubeen/compliance-chatbot/backend/main.py", line 5, in <module>
    from backend.api.v1.openai_compat import router as openai_router
ImportError: cannot import name 'router' from 'backend.api.v1.openai_compat' (/home/mubeen/compliance-chatbot/backend/api/v1/openai_compat.py)
Graph compiled successfully.
AI Service Initialized (Index loaded and graph agent ready).
